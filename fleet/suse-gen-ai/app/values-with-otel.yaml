global:
  tls:
    source: "secret"
ingress:
  tls: true
ollama:
  #To learn more about the entries, helm show values oci://dp.apps.rancher.io/charts/ollama
  enabled: true
  ollama:
    models:
      pull:
        - "llama3.2:3b"
        - "gemma3:4b"
        - "gemma:2b"
        - "deepseek-r1:8b"
        - "qwen2.5-coder:7b"
      run:
        - "deepseek-r1:8b"
    gpu:
      enabled: true
      type: "nvidia"
      number: 1
  runtimeClassName: "nvidia"
  persistentVolume:
    enabled: true
    size: 100Gi
open-webui:
  #To learn more about the entries, helm show values oci://dp.apps.rancher.io/charts/open-webui
  enabled: true
  ollamaUrls:
    - http://suse-gen-ai-ollama.suse-gen-ai.svc.cluster.local:11434
  persistence:
    enabled: true
    size: 20Gi
  ollama:
    enabled: false
  pipelines:
    enabled: true
    persistence:
      enabled: true
    extraEnvVars:
      - name: PIPELINES_URLS
        value: "https://raw.githubusercontent.com/SUSE/suse-ai-observability-extension/refs/heads/main/integrations/oi-filter/suse_ai_filter.py"
      - name: OTEL_SERVICE_NAME
        value: "Open WebUI"
      - name: OTEL_EXPORTER_HTTP_OTLP_ENDPOINT
        value: "http://opentelemetry-collector.suse-observability.svc.cluster.local:4318"
      - name: PRICING_JSON
        value: "https://raw.githubusercontent.com/SUSE/suse-ai-observability-extension/refs/heads/main/integrations/oi-filter/pricing.json"
  ingress:
    annotations:
      cert-manager.io/cluster-issuer: local-issuer
    class: nginx
    host: chat.lab.suse
  extraEnvVars:
    - name: DEFAULT_MODELS
      value: "gemma:2b"
    - name: DEFAULT_USER_ROLE
      value: "user"
    - name: WEBUI_NAME
      value: "SUSE AI"
    - name: ENABLE_SIGNUP
      value: "true"
    - name: GLOBAL_LOG_LEVEL
      value: INFO
    - name: RAG_EMBEDDING_MODEL
      value: "sentence-transformers/all-MiniLM-L6-v2"
    - name: VECTOR_DB
      value: "milvus"
    - name: MILVUS_URI
      value: http://suse-gen-ai-milvus.suse-gen-ai.svc.cluster.local:19530
    - name: INSTALL_NLTK_DATASETS
      value: "true"
    - name: ENV
      value: "dev"
    - name: OPENAI_API_KEY
      value: "0p3n-w3bu!"
milvus:
  enabled: true
  cluster:
    enabled: false
  standalone:
    persistence:
      persistentVolumeClaim:
        size: 50Gi
  etcd:
    replicaCount: 1
    persistence:
      enabled: true
  minio:
    mode: standalone
    rootUser: "admin"
    rootPassword: "adminminio"
    persistence:
      size: 20Gi
    resources:
      requests:
        memory: 1024Mi
  kafka:
    enabled: false
    persistence:
      enabled: true
pytorch:
  enabled: false
